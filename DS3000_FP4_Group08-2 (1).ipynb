{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2021</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Zillow Housing Price Predictor</h3> </center>\n",
    "<center><h4>Jasmine Liu, Sruthi Chintalacharuvu, Ben Wyant</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab link: https://colab.research.google.com/drive/1l3S6hAnf5_FbQYrV8411KrUFIOF55cCV?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "COVID-19 has affected the real estate market in the United States. With 44% of homes sales occurring in the south, we wanted to observe what was affecting the prices of the houses sold in this region. To acquire the necessary data, we scraped Zillow for recently sold houses in five southern states. Next, we utilized four machine learning algorithms to try to obtain the most accurate prediction model. In the process, we performed feature selection and hyperparameter tuning to determine that Linear Regression had the best performance on our dataset. However, results showed that we did not have a sufficient enough dataset to predict which features had the most influence on the selling price of houses, nor did our models very accurately predict the prices as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Problem Statement</h4>\n",
    "\n",
    "Our group would like to gather more insight on housing prices in the southern states of the U.S. where the country is seeing an increasing amount of home sales. With the recovering economy from COVID-19, more buyers are entering the housing market and the housing prices are slowly increasing. Recent studies show that the Southern states accounted for almost 44% of home sales in the past few years. Therefore, our group’s goal is to analyze the characteristics of houses in the South and determine whether there is a correlation between these features to predict the housing prices. Zillow is one of the largest real estate websites in the United States and many people turn to Zillow when buying and selling real estate. We want to determine whether prices of the houses listed for sale are determined by the data made public on the site or if there is hidden data and other non-quantifiable characteristics such as modernity of a home that is being used in the listing prices. If our model can accurately predict housing prices for sold homes without overfitting the data, we should be able to predict whether houses listed currently are being priced too low, high, or pretty close to the expected selling price.\n",
    "\n",
    "\n",
    "\n",
    "<h4>Significance of the Problem</h4>\n",
    "\n",
    "It’s important to tackle this problem because data science is beginning to play a huge role in how real estate is valued and purchased. Zillow has begun buying homes using their algorithm and now many large investors are looking towards data scientists to guide them in investing in real estate. Using geographic information and other home features, we want to see how accurately we can predict housing prices and whether or not these home features have a noticeable impact on housing prices. This could be useful in allowing fair assessments of homes to be made so neither buyers or sellers are pressured into bad deals. \n",
    "\n",
    "\n",
    "<h4>Questions</h4>\n",
    "\n",
    "Some questions that we have regarding our problem and its significance include:\n",
    "- What features have more influence on the house price?\n",
    "- How do sites like Zillow determine which features are most important for their house price predictors?\n",
    "- Is there a ML algorithm that will perform significantly better than the rest between k-nearest neighbors (kNN), Linear Regression, Lasso Regression, and Ridge Regression? If so, why did that one perform better?\n",
    "- What methods of preprocessing and hyperparameter tuning will provide the best result on our test data?\n",
    "\n",
    "\n",
    "\n",
    "<h4>References<h4>\n",
    "\n",
    "Dowell, E. K. P. (2021, October 9). Remote working, commuting time, life events all affect home buyers' decisions. Census.gov. Retrieved December 5, 2021, from https://www.census.gov/library/stories/2021/10/zillow-and-census-bureau-data-show-pandemics-impact-on-housing-market.html. \n",
    "\n",
    "Friedman, N. (2021, November 22). U.S. home sales on track for biggest year in 15 years. The Wall Street Journal. Retrieved December 5, 2021, from https://www.wsj.com/articles/u-s-home-sales-on-track-for-biggest-year-in-15-years-11637593790. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "\n",
    "We scraped our data from Zillow from multiple cities in five Southern states - Florida, Georgia, Alabama, South Carolina, and Tennessee. While picking cities to retrieve data from, we determined the top 20-25 most populated cities in the five states above. We searched the site for houses that were recently sold, and we scraped for features that could be helpful for determining the final price of the house. \n",
    "\n",
    "\n",
    "Links to original data sources:\n",
    "\n",
    "- Florida: https://www.zillow.com/homes/florida_rb/\n",
    "- Georgia: https://www.zillow.com/homes/georgia_rb/\n",
    "- Alabama: https://www.zillow.com/homes/alabama_rb/\n",
    "- South Carolina: https://www.zillow.com/homes/south-carolina_rb/\n",
    "- Tennessee: https://www.zillow.com/homes/tennessee_rb/\n",
    "\n",
    "The dataset we are using for our project is about real estate information scraped from Zillow for houses in the southern states in the U.S. The dataset includes 1062 rows/samples. Our features include year sold, ZIP, beds, bath, sqft, month sold, broker, city, and state. Our target variable is the predicted price. \n",
    "\n",
    "Our features:\n",
    "\n",
    "\t- city_sold: the city the house was sold in\n",
    "\t- state_sold: the state the house was sold in\n",
    "\t- zip_code: the house’s zip code\n",
    "\t- bds: the number of bedrooms\n",
    "\t- ba: the number of bathrooms\n",
    "\t- sqft: the square footage of the house\n",
    "\t- broker_name: brokerage selling the house\n",
    "\t- month_sold: the month sold\n",
    "\t- year_sold: the year sold\n",
    "Our target:\n",
    "\n",
    "\t- price_sold: the price the house was sold for\n",
    "\n",
    "Our data scraping code can be found here: https://github.com/jasmineliu0114/Zillow-Housing-Price-Predictor/blob/main/FP2_Dataset.ipynb\n",
    "\n",
    "Our resulting dataset: \n",
    "https://github.com/jasmineliu0114/Zillow-Housing-Price-Predictor/blob/main/real_estate_prices_in_the_south.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "Our predictive model is a regression model that will use the features of the houses we scraped from Zillow to predict the house prices. We think these are important predictors because the features listed on an online housing website are the features that are important to home buyers when evaluating potential future homes. This is a supervised ML problem because it is a regression problem which is a subfield of supervised learning. Regression requires a labeled dataset and uses independent variables (features) to predict the dependent variable (price), therefore, this is a supervised ML problem. \n",
    "\n",
    "Our features/independent variables: \n",
    "\n",
    "    - city_sold, state_sold, zip_code, bds, ba, sqft, broker_name, month_sold, year_sold\n",
    "\n",
    "Our target/outcome variable: \n",
    "\n",
    "\t- price_sold\n",
    "\n",
    "We are planning to use k-nearest neighbors (kNN), Linear Regression, Lasso Regression, and Ridge Regression. To apply kNN we assume that the value can be approximated by some local values of features - an approximation can be made by the distance between some of the feature values and not the model’s entire distribution. To apply Linear Regression we assume that all the values can be modeled numerically and that there is some line of best fit using a variety of features that can best approximate a house price. The same assumptions to perform Linear Regression can be made for Lasso and Ridge Regression. The data needs to be able to be regularized and lasso and ridge will help reduce bias and variance. We plan to try all of these algorithms because we are uncertain if one specific algorithm would give us better results over the others. However, we do think that Linear Regression will give us the worst result because it does not account for bias or weighting features.\n",
    "\n",
    "Additionally, we plan to use RFE to select the most important features. For our RFE, we plan to use a Decision Tree regressor to recursively eliminate features. This will help us determine if the use of just the important features will affect R-squared values for the training and test sets. We will also use one hot encoding to turn categorical data into numerical data for features such as state, city, and month sold. We plan to plot all of our features against the target house prices as scatterplots to visualize the relationship between each feature with our target value. In addition, we plan on plotting the expected vs predicted house prices. This graph would be a scatterplot with a \"perfect prediction\" line in order to visualize the accuracy of our estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>city_sold</th>\n",
       "      <th>state_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>broker_name</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$232,600</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32234</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$495,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$473,500</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2,360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$343,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$300,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1,952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>$255,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>$220,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1,107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>$280,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>$290,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>$52,500</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1062 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zillow_df = pd.read_csv(\"real_estate_prices_in_the_south.csv\")\n",
    "zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that in our dataset, there were some rows with empty sqft, bds, and/or ba columns. First, we counted how many rows had empty values to decide if removing those rows would greatly affect the size of our data. After determining that the number would not be too large, we removed the empty rows from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "30\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# check how many listings have \"-- \" sqft\n",
    "emptySqft = (zillow_df['sqft'] == '-- ').sum(axis=0)\n",
    "print(emptySqft) # 32 listings have no value for sqft \n",
    "\n",
    "emptyBds = (zillow_df['bds'] == '-- ').sum(axis=0)\n",
    "print(emptyBds) # 30 listings have no value for number of bedrooms\n",
    "\n",
    "emptyBa = numDash = (zillow_df['ba'] == '-- ').sum(axis=0)\n",
    "print(emptyBa) # 9 listings have no value for number of bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>city_sold</th>\n",
       "      <th>state_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>broker_name</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$232,600</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32234</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$495,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$473,500</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2,360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$343,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$300,000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1,952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>$255,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>$220,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1,107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>$280,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>$290,000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>$52,500</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removes rows where value is \"-- \"\n",
    "zillow_df = zillow_df[zillow_df[\"sqft\"] != '-- ']\n",
    "zillow_df = zillow_df[zillow_df[\"bds\"] != '-- ']\n",
    "zillow_df = zillow_df[zillow_df[\"ba\"] != '-- ']\n",
    "zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our data is currently formatted as strings, as scraped from Zillow. However, having our numerical data represented as strings is useless so we are going through and converting all the numerical data currently represented as strings into numbers which we can normalize and perform data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_million(price):\n",
    "    \"\"\"Converts prices over a million to the full number written out. Also converts all prices to integers. \n",
    "    Parameters:\n",
    "        price (string): the string price to convert\n",
    "    Returns:\n",
    "        (int): the converted price to integer\n",
    "    \"\"\"\n",
    "    if 'M' in price:\n",
    "        without_m = price[0:len(price) - 1]\n",
    "        split = without_m.strip().split('.')\n",
    "        combined = int(split[0] + split[1])\n",
    "        return combined * 10000\n",
    "    elif ',' in price:\n",
    "        without_comma = price.strip().split(',')\n",
    "        comb = without_comma[0] + without_comma[1]\n",
    "        return int(comb)\n",
    "    else:\n",
    "        return int(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ef45c492f63b>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  zillow_df['price_sold'] = zillow_df['price_sold'].str.replace('$', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>city_sold</th>\n",
       "      <th>state_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>broker_name</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232600</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32234</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473500</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>255000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>220000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>280000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>290000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>52500</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removes the commas from the square footage\n",
    "zillow_df['sqft'] = zillow_df['sqft'].str.replace(',','')\n",
    "\n",
    "# removes the dollar sign from the price_sold column\n",
    "zillow_df['price_sold'] = zillow_df['price_sold'].str.replace('$', '')\n",
    "\n",
    "# fixes million dollar value houses and converts price_sold column to numerical values\n",
    "zillow_df['price_sold'] = zillow_df['price_sold'].map(convert_million)\n",
    "\n",
    "# converting columns into int/float values\n",
    "zillow_df['sqft'] = zillow_df['sqft'].astype('int')\n",
    "zillow_df['zip_code'] = zillow_df['zip_code'].astype('int')\n",
    "zillow_df['bds'] = zillow_df['bds'].astype('int')\n",
    "zillow_df['ba'] = zillow_df['ba'].astype('float')\n",
    "zillow_df['month_sold'] = zillow_df['month_sold'].astype('int')\n",
    "zillow_df['year_sold'] = zillow_df['year_sold'].astype('int')\n",
    "zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the categorical values of our dataset, we determined that the broker_name column is unlikely to be useful for us. We came to this conclusion because more than 300 rows do not contain broker_name values. Removing those rows would take away too many data points. Additionally, because we have a large range of different brokers, the NaN values would be classified as one broker if we were to keep its value, which would be a much larger group than any of the other individual brokers and not having an even sample of brokers could negatively effect our algorithm's performance after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# check how many listings have NaN broker_name\n",
    "count = 0\n",
    "for x in range(1002):\n",
    "    if type(zillow_df['broker_name'].iloc[x]) == float:\n",
    "        if math.isnan(zillow_df['broker_name'].iloc[x]):\n",
    "            count +=1\n",
    "\n",
    "count # 362 rows have NaN broker_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>city_sold</th>\n",
       "      <th>state_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232600</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32234</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1406</td>\n",
       "      <td>10</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1832</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473500</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2360</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>255000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>220000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>280000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1366</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>290000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1283</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>52500</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop the column containing broker names since 30% of values are N/A\n",
    "\n",
    "zillow_df.drop('broker_name', axis=1, inplace=True)\n",
    "zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed that there were some outliers in the year_sold column. These were probably typos on Zillow's end, but as integer values, these outliers will have a negative effect on the accuracy of our machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>city_sold</th>\n",
       "      <th>state_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1832</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473500</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2360</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300000</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>fl</td>\n",
       "      <td>32206</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>255000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>220000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>280000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1366</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>290000</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1283</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>52500</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>tn</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removes outliers from year_sold column\n",
    "zillow_df = zillow_df[zillow_df[\"year_sold\"] <= 2021]\n",
    "zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order for us to be able to use our categorical values, we used one-hot encoding to represent these categorical features as numerical values. Using one-hot encoding is preferred over simply assigning a number to each categorical value because we do not want the size of the number to affect our machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_sold_Aiken</th>\n",
       "      <th>city_sold_Alabaster</th>\n",
       "      <th>city_sold_Alafaya</th>\n",
       "      <th>city_sold_Albany</th>\n",
       "      <th>city_sold_Anderson</th>\n",
       "      <th>city_sold_Athens</th>\n",
       "      <th>city_sold_Atlanta</th>\n",
       "      <th>city_sold_Auburn</th>\n",
       "      <th>city_sold_Bartlett</th>\n",
       "      <th>city_sold_Berea</th>\n",
       "      <th>...</th>\n",
       "      <th>city_sold_Tucker</th>\n",
       "      <th>city_sold_Tullahoma</th>\n",
       "      <th>city_sold_Tuscaloosa</th>\n",
       "      <th>city_sold_Valdosta</th>\n",
       "      <th>city_sold_Woodstock</th>\n",
       "      <th>state_sold_al</th>\n",
       "      <th>state_sold_fl</th>\n",
       "      <th>state_sold_ga</th>\n",
       "      <th>state_sold_sc</th>\n",
       "      <th>state_sold_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 120 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "encoded_df = encoder.fit_transform(zillow_df[[\"city_sold\", \"state_sold\"]])\n",
    "\n",
    "# dataframe of one-hot encoded features\n",
    "encoded_features_df = pd.DataFrame(encoded_df, columns = encoder.get_feature_names([\"city_sold\", \"state_sold\"]))\n",
    "\n",
    "encoded_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sold</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>bds</th>\n",
       "      <th>ba</th>\n",
       "      <th>sqft</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>city_sold_Aiken</th>\n",
       "      <th>city_sold_Alabaster</th>\n",
       "      <th>city_sold_Alafaya</th>\n",
       "      <th>...</th>\n",
       "      <th>city_sold_Tucker</th>\n",
       "      <th>city_sold_Tullahoma</th>\n",
       "      <th>city_sold_Tuscaloosa</th>\n",
       "      <th>city_sold_Valdosta</th>\n",
       "      <th>city_sold_Woodstock</th>\n",
       "      <th>state_sold_al</th>\n",
       "      <th>state_sold_fl</th>\n",
       "      <th>state_sold_ga</th>\n",
       "      <th>state_sold_sc</th>\n",
       "      <th>state_sold_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495000</td>\n",
       "      <td>32081</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1832</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473500</td>\n",
       "      <td>32256</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2360</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>343000</td>\n",
       "      <td>32257</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300000</td>\n",
       "      <td>32221</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>32206</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>255000</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>220000</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>280000</td>\n",
       "      <td>37029</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1366</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>290000</td>\n",
       "      <td>37055</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1283</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>52500</td>\n",
       "      <td>37055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 127 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creates new dataframe of only numerical features by resetting indices \n",
    "# and dropping city_sold and state_sold columns from zillow_df\n",
    "numerical_zillow_df = zillow_df.reset_index().drop(columns=['index','city_sold', 'state_sold'], axis=1, inplace=False)\n",
    "\n",
    "# merges dataframe with numerical features and dataframe with one-hot encoded features\n",
    "encoded_zillow_df = pd.merge(numerical_zillow_df, encoded_features_df, left_index=True, right_index=True)\n",
    "encoded_zillow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization\n",
    "\n",
    "The variables used in the heatmap below are quantitative features which we could use to check correlation between each other to understand how much relation one feature had with another. This heatmap mostly shows what we expected. There is a positive correlation for beds, baths, sqft, and price for the houses in the data set. This makes sense because what the general trend is that, as a house gets larger, the price increases along with the other features as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "Text(0.5, 1.0, 'Zillow Housing Data Correlation Matrix Heatmap')"
      ]
     },
     "metadata": {
      "image/png": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a correlation heatmap using seaborn's heatmap feature\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# drop the categorical columns of the data table\n",
    "heatmap_df = zillow_df.drop(['year_sold', 'zip_code', 'month_sold'], axis=1)\n",
    "\n",
    "heatmap = sns.heatmap(heatmap_df.corr(), annot=True)\n",
    "heatmap.set_title('Zillow Housing Data Correlation Matrix Heatmap', fontdict={'fontsize': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/T489sny/Screen-Shot-2021-12-10-at-3-00-12-PM.png\" width=450/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data visualizations below are plotting the mean number of beds, baths, sqft, month sold, and year sold vs. the mean price sold for each city. The graphs represent the relationship between the mean price sold and each of the feature values listed above per city. The graph represents the relationship between the locations of the houses and the numerical values compared to the price sold. The larger the bubble, the more sold homes a city had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unsupported"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a bubble plot showing price vs all other columns for every city\n",
    "\n",
    "#group the houses by the city they were sold in\n",
    "grouped_df = zillow_df.groupby('city_sold')\n",
    "grouped_df.head()\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# maintain a list of what state each city is in to color it on the visualization\n",
    "city_states = {}\n",
    "for row in zillow_df.itertuples():\n",
    "    if not row[2] in city_states.keys(): # row[2] is the city_sold and row[3] is the state_sold (the state which the city is in)\n",
    "        city_states[row[2]] = row[3]\n",
    "\n",
    "# turn the dictionary into a dataframe and sort it by index so that we can combine it with the main visualization dataframe\n",
    "city_state_df = pd.DataFrame.from_dict(city_states, orient='index').sort_index().rename(columns={0: 'state'})\n",
    "\n",
    "# the different features we want to test against price for houses in each city\n",
    "x_axes = ['bds', 'ba', 'sqft', 'month_sold', 'year_sold']\n",
    "\n",
    "# group the cities by the mean values to get the avg value for each feature to plot\n",
    "grouped_counts = grouped_df.count().rename(columns={'state_sold': 'listing_count'})\n",
    "\n",
    "# add the number of listing counts to the visualization dataframe to be used to create the bubble size\n",
    "visualization_df = grouped_df.mean().join(grouped_counts['listing_count'])\n",
    "\n",
    "# add the state the listing is in to the visualization dataframe to be used to create the bubble colors\n",
    "visualization_df = visualization_df.join(city_state_df)\n",
    "\n",
    "# map to use for x axis titles for each plot\n",
    "plt_titles = {'bds': 'Number of Bedrooms', 'ba': 'Number of Bathrooms', 'sqft': 'Square Feet (House Size)',\n",
    "                'month_sold': 'Month Sold', 'year_sold': 'Year Sold'}\n",
    "\n",
    "# loop through and create the plots for each feature vs the price\n",
    "for feature in x_axes:\n",
    "    fig = px.scatter(visualization_df, x=feature, y='price_sold', size='listing_count', \n",
    "                    hover_name=visualization_df.index, color='state', title=('Price Sold vs. ' + plt_titles.get(feature)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/87HgpTM/Bds-vs-Price-sold.png\" width=1200 />\n",
    "<img src=\"https://i.ibb.co/0XhPbd5/Ba-vs-Price-sold.png\" width=1200 />\n",
    "<img src=\"https://i.ibb.co/dtymmGf/sqft-vs-price.png\" width=1200 />\n",
    "<img src=\"https://i.ibb.co/H2kVJfg/month-sold-vs-price.png\" width=1200 />\n",
    "<img src=\"https://i.ibb.co/ZVWYbyf/year-sold-vs-price.png\" width=1200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seven graphs below plot each feature value in our dataset against the target variable: price sold. The graphs help visualize the relationship between each feature and the target value, which gives some insight on which feature values are more influential over the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "features = ['state_sold', 'zip_code', 'bds', 'ba', 'sqft', 'month_sold', 'year_sold']\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 4.5))  # 8\"-by-4.5\" Figure\n",
    "    sns.scatterplot(data=zillow_df, x=feature, y='price_sold', hue='price_sold', \n",
    "    palette='cool', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/Nr8LbQ7/Top-2-SS.png\" alt=\"Top-2-SS\" border=\"0\">\n",
    "<img src=\"https://i.ibb.co/gDBLCvk/3-4-SS.png\" alt=\"3-4-SS\" border=\"0\">\n",
    "<img src=\"https://i.ibb.co/3mZ5dCj/5-6-SS.png\" alt=\"5-6-SS\" border=\"0\">\n",
    "<img src=\"https://i.ibb.co/6HxrmTQ/Last-1-SS.png\" alt=\"Last-1-SS\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization below shows the distribution of the price sold of all the houses in our dataset represented as a histogram. This graph shows us that the prices are right skewed towards extremely expensive houses, some of which are major outliers in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "histplot = sns.histplot(zillow_df['price_sold'])\n",
    "histplot.set(title='Price Sold Histogram', xlabel='Price Sold (in millions of $)', ylabel='Number of Entries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/cQdyTGb/Screen-Shot-2021-12-10-at-3-39-15-PM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the features and target variables\n",
    "features = encoded_zillow_df.drop(\"price_sold\", axis=1)\n",
    "target = encoded_zillow_df[\"price_sold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the dataset into training and testing sets using random_state of 3000\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "estimators = {\n",
    "    \"Linear Regression\" : LinearRegression(), \n",
    "    \"Ridge\" : Ridge(),\n",
    "    \"Lasso\" : Lasso(),\n",
    "    \"k-Nearest Neighbor\" : KNeighborsRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "\tR-squared value for training set:  0.5805969737999006\n",
      "\tR-squared value for testing set:  0.30666275619879235\n",
      "\tMean squared error for training set:  51684528775.1\n",
      "\tMean squared error for testing set:  341483766691.304\n",
      "Ridge:\n",
      "\tR-squared value for training set:  0.5772229887984481\n",
      "\tR-squared value for testing set:  0.30841063706755034\n",
      "\tMean squared error for training set:  52100316964.504074\n",
      "\tMean squared error for testing set:  340622897109.9747\n",
      "Lasso:\n",
      "\tR-squared value for training set:  0.5805838467453919\n",
      "\tR-squared value for testing set:  0.3065980590751112\n",
      "\tMean squared error for training set:  51686146468.7839\n",
      "\tMean squared error for testing set:  341515631440.654\n",
      "k-Nearest Neighbor:\n",
      "\tR-squared value for training set:  0.4859133627662481\n",
      "\tR-squared value for testing set:  0.11557517397126582\n",
      "\tMean squared error for training set:  63352727412.90475\n",
      "\tMean squared error for testing set:  435598583009.60834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+13, tolerance: 9.243e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# algorithm performance with all features\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "    model = estimator_object\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    print(estimator_name + ':')\n",
    "    print(\"\\tR-squared value for training set: \", r2_score(y_train, model.predict(X_train)))\n",
    "    print(\"\\tR-squared value for testing set: \", r2_score(y_test, model.predict(X_test)))\n",
    "    print(\"\\tMean squared error for training set: \", mean_squared_error(y_train, model.predict(X_train)))\n",
    "    print(\"\\tMean squared error for testing set: \", mean_squared_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance of our algorithms, there is indication of underfitting, as our training set has poor performance, and the algorithms poorly generalizes to our testing set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features after RFE:\n",
      "\tzip_code\n",
      "\tba\n",
      "\tsqft\n",
      "\n",
      "Linear Regression performance with selected features:\n",
      "\tR-squared value for training set:  0.3834913808937884\n",
      "\tR-squared value for testing set:  0.2605601956134862\n",
      "\tMean squared error for training set:  75974553052.19876\n",
      "\tMean squared error for testing set:  364190286762.9393\n",
      "\n",
      "Ridge performance with selected features:\n",
      "\tR-squared value for training set:  0.3834911548565215\n",
      "\tR-squared value for testing set:  0.260553604811704\n",
      "\tMean squared error for training set:  75974580907.57626\n",
      "\tMean squared error for testing set:  364193532877.0608\n",
      "\n",
      "Lasso performance with selected features:\n",
      "\tR-squared value for training set:  0.3834913808824374\n",
      "\tR-squared value for testing set:  0.26056014867081256\n",
      "\tMean squared error for training set:  75974553053.59758\n",
      "\tMean squared error for testing set:  364190309883.2334\n",
      "\n",
      "k-Nearest Neighbor performance with selected features:\n",
      "\tR-squared value for training set:  0.4859133627662481\n",
      "\tR-squared value for testing set:  0.11557517397126582\n",
      "\tMean squared error for training set:  63352727412.90475\n",
      "\tMean squared error for testing set:  435598583009.60834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Ridge was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Ridge was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Ridge was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Ridge was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Lasso was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Lasso was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Lasso was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but Lasso was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# algorithm performance with selected features\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 3)\n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Selected features after RFE:')\n",
    "for x in range(len(select.get_support())):\n",
    "    if select.get_support()[x]:\n",
    "        print('\\t' + features.columns[x])\n",
    "\n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "    model = estimator_object.fit(X=X_train_selected, y=y_train)\n",
    "    print('\\n' + estimator_name + ' performance with selected features:')\n",
    "    print(\"\\tR-squared value for training set: \", r2_score(y_train, model.predict(X_train_selected)))\n",
    "    print(\"\\tR-squared value for testing set: \", r2_score(y_test, model.predict(X_test_selected)))\n",
    "    print(\"\\tMean squared error for training set: \", mean_squared_error(y_train, model.predict(X_train_selected)))\n",
    "    print(\"\\tMean squared error for testing set: \", mean_squared_error(y_test, model.predict(X_test_selected)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since feature selection performed worse for all of our models, we will continue to just use the training and testing sets with all features. Below, we use GridSearch to hyperparameter tune each of our machine learning algorithms to try to limit the underfitting of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for each machine learning algorithm\n",
    "lin_reg_param_grid = {'copy_X': [True, False], 'fit_intercept': [True, False], 'normalize': [True, False]}\n",
    "ridge_param_grid = {'alpha':[.001, .01, .1, 1, 10, 100]}\n",
    "lasso_param_grid = {'alpha':[.001, .01, .1, 1, 10, 100]}\n",
    "knn_param_grid = {\"n_neighbors\":[1, 5, 10], \"metric\": ['euclidean', 'manhattan', 'minkowski']}\n",
    "\n",
    "param_grid = {\"Linear Regression\" : lin_reg_param_grid, \n",
    "    \"Ridge\" : ridge_param_grid,\n",
    "    \"Lasso\" : lasso_param_grid,\n",
    "    \"k-Nearest Neighbor\" : knn_param_grid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Linear Regression:  {'copy_X': True, 'fit_intercept': False, 'normalize': True}\n",
      "Training set score with best parameters:  0.5805938561640318\n",
      "Test set score with best parameters:  0.30662886777504217\n",
      "\n",
      "Best parameters for Ridge:  {'alpha': 10}\n",
      "Training set score with best parameters:  0.5295133073466725\n",
      "Test set score with best parameters:  0.3020890883237285\n",
      "\n",
      "Best parameters for Lasso:  {'alpha': 100}\n",
      "Training set score with best parameters:  0.5792756064380318\n",
      "Test set score with best parameters:  0.30572238522234185\n",
      "\n",
      "Best parameters for k-Nearest Neighbor:  {'metric': 'euclidean', 'n_neighbors': 10}\n",
      "Training set score with best parameters:  0.4116320032055797\n",
      "Test set score with best parameters:  0.12916851019272768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+13, tolerance: 7.908e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+13, tolerance: 6.340e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+13, tolerance: 7.269e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+13, tolerance: 6.815e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+13, tolerance: 7.908e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+13, tolerance: 6.340e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+13, tolerance: 7.269e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+13, tolerance: 6.815e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+13, tolerance: 7.908e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+13, tolerance: 6.340e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+13, tolerance: 7.269e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+13, tolerance: 6.815e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+13, tolerance: 7.908e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+13, tolerance: 6.340e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+13, tolerance: 7.269e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+13, tolerance: 6.815e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+13, tolerance: 6.340e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+13, tolerance: 7.269e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+13, tolerance: 6.815e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+13, tolerance: 8.633e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+13, tolerance: 9.243e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GridSearch using all features\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "    grid_search = GridSearchCV(estimator_object, param_grid[estimator_name], cv=5)\n",
    "    grid_search.fit(X=X_train, y=y_train)\n",
    "\n",
    "    print(\"\\nBest parameters for \" + estimator_name+ \": \", grid_search.best_params_)\n",
    "    print(\"Training set score with best parameters: \", grid_search.score(X_train, y_train))\n",
    "    print(\"Test set score with best parameters: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_estimators = {\n",
    "    \"Linear Regression\" : LinearRegression(copy_X=True, fit_intercept=False, normalize=True), \n",
    "    \"Ridge\" : Ridge(alpha=10),\n",
    "    \"Lasso\" : Lasso(alpha=100),\n",
    "    \"k-Nearest Neighbor\" : KNeighborsRegressor(metric='euclidean', n_neighbors=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "\tR-squared value for training set:  0.5805938561640318\n",
      "\tR-squared value for testing set:  0.30662886777504217\n",
      "\tMean squared error for training set:  51684912972.472694\n",
      "\tMean squared error for testing set:  341500457481.6703\n",
      "Ridge:\n",
      "\tR-squared value for training set:  0.5295133073466725\n",
      "\tR-squared value for testing set:  0.3020890883237285\n",
      "\tMean squared error for training set:  57979750945.19424\n",
      "\tMean squared error for testing set:  343736398217.35486\n",
      "Lasso:\n",
      "\tR-squared value for training set:  0.5792756064380318\n",
      "\tR-squared value for testing set:  0.30572238522234185\n",
      "\tMean squared error for training set:  51847365581.633675\n",
      "\tMean squared error for testing set:  341946919977.8128\n",
      "k-Nearest Neighbor:\n",
      "\tR-squared value for training set:  0.4116320032055797\n",
      "\tR-squared value for testing set:  0.12916851019272768\n",
      "\tMean squared error for training set:  72506683931.65247\n",
      "\tMean squared error for testing set:  428903567421.87354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+13, tolerance: 9.243e+09\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n",
      "/opt/python/envs/default/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator_name, estimator_object in tuned_estimators.items():\n",
    "    model = estimator_object\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    print(estimator_name + ':')\n",
    "    print(\"\\tR-squared value for training set: \", r2_score(y_train, model.predict(X_train)))\n",
    "    print(\"\\tR-squared value for testing set: \", r2_score(y_test, model.predict(X_test)))\n",
    "    print(\"\\tMean squared error for training set: \", mean_squared_error(y_train, model.predict(X_train)))\n",
    "    print(\"\\tMean squared error for testing set: \", mean_squared_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "For our model training, we compared four different machine learning algorithms: Linear Regression, Ridge, Lasso, and k-Nearest Neighbors.  In the end, Linear Regression had the best performance using the following parameters: copy_X=True, fit_intercept=False, and normalize=True. However, even though Linear Regression performed the best, none of the algorithms should be used for our predictive model, as the overall results were fairly low. Therefore, the features in our dataset should not be used to predict the prices of houses in the southern United States.\n",
    "\n",
    "We also believe that our results should not be accepted at face value due to dataset bias. For instance, our month_sold and year_sold columns are not well represented, as most of the houses in our dataset were sold in October or November, and all of them were sold in 2021. In addition, our data may not be a good representation of all sold houses during that time period, as our dataset was very small and is only scraped from one source.\n",
    "\n",
    "From our training process, we learned that we needed a much larger and more diverse dataset. Since we only scraped Zillow for the most recently sold houses, all of our data points only covered a range of a few months, and they were all sold in the same year. We recommend that for future work, obtaining data that represents a wider range of months and years would be beneficial to the model training process. Additionally, future work should utilize a much larger dataset to avoid skewed data and to hopefully provide more insight when running machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "\n",
    "All three team members contributed to every aspect of the project. For part 1, everybody contributed to determining which project we wanted to pursue and then what we wanted to learn and achieve throughout our project. Generating the data in part 2 was also a team effort as Ben found the data sets and figured out how to get around the Zillow's captcha, Sruthi determined how to scrape the data and which data from Zillow was important to collect, then Jasmine compiled the code to do so on a Jupyter notebook and put that data onto github. For part 3, everyone participated in wrangling the data. Sruthi did the bulk of noting down why we were making the decisions we did and then compiled those decisions in our writing/descriptions, Ben took charge of creating the data visualizations which we chose to make as a group, and Jasmine wrote the code to train and test the models. Once again, everybody contributed to the write-up in part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
